{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (\n",
    "    RobertaModel,\n",
    "    AutoTokenizer,\n",
    "    RobertaTokenizer,AutoModelForSequenceClassification\n",
    ")\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Import the dataset loader\n",
    "from mamkit.data.datasets import MMUSEDFallacy, InputMode\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define constants\n",
    "MAX_TEXT_LEN = 128   # Maximum number of tokens for text\n",
    "BATCH_SIZE = 16       \n",
    "NUM_CLASSES = 6\n",
    "LEARNING_RATE = 2e-5\n",
    "EPOCHS = 10\n",
    "SEED = 42\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# Define fallacy mapping for easier reference\n",
    "fallacy_mapping = {\n",
    "    0: \"Appeal to Emotion\",\n",
    "    1: \"Appeal to Authority\",\n",
    "    2: \"Ad Hominem\",\n",
    "    3: \"False Cause\",\n",
    "    4: \"Slippery Slope\",\n",
    "    5: \"Slogans\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "base_data_path = Path(os.getcwd()).joinpath('../testdataset')\n",
    "base_data_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# MM-USED-fallacy dataset with text only\n",
    "mm_used_fallacy_loader = MMUSEDFallacy(\n",
    "    task_name='afc',  # Argumentative Fallacy Classification\n",
    "    input_mode=InputMode.TEXT_ONLY,  # Using only text\n",
    "    base_data_path=base_data_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examining the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Mapping audio data...: 100%|██████████| 3388/3388 [00:01<00:00, 2643.82it/s]\n",
      "Building AFC Context: 100%|██████████| 3388/3388 [00:00<00:00, 13442.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 3388 samples\n",
      "        dialogue_indexes                                 dialogue_sentences  \\\n",
      "0           [84, 85, 86]  [These people depend upon all of us for the li...   \n",
      "1        [146, 147, 148]  [In mine, I happen to believe in the people an...   \n",
      "2        [143, 144, 145]  [And, incidentally, I might say that with rega...   \n",
      "3        [228, 229, 230]  [All history tells us that that's a mistake., ...   \n",
      "4        [294, 295, 296]  [They see this tremendous influx and swamping ...   \n",
      "...                  ...                                                ...   \n",
      "3383  [1068, 1069, 1070]  [We have wars going on with Russia and Ukraine...   \n",
      "3384  [1069, 1070, 1071]  [We're going to end up in a Third World War, a...   \n",
      "3385  [1070, 1071, 1072]  [I rebuilt our entire military., She gave a lo...   \n",
      "3386  [1071, 1072, 1073]  [She gave a lot of it away to the Taliban., Sh...   \n",
      "3387  [1072, 1073, 1074]  [She gave it to Afghanistan., What these peopl...   \n",
      "\n",
      "                                               dialogue dialogue_id  \\\n",
      "0     These people depend upon all of us for the lit...     10_1984   \n",
      "1     In mine, I happen to believe in the people and...     10_1984   \n",
      "2     And, incidentally, I might say that with regar...     10_1984   \n",
      "3     All history tells us that that's a mistake. Wh...     10_1984   \n",
      "4     They see this tremendous influx and swamping o...     10_1984   \n",
      "...                                                 ...         ...   \n",
      "3383  We have wars going on with Russia and Ukraine....     48_2024   \n",
      "3384  We're going to end up in a Third World War, an...     48_2024   \n",
      "3385  I rebuilt our entire military. She gave a lot ...     48_2024   \n",
      "3386  She gave a lot of it away to the Taliban. She ...     48_2024   \n",
      "3387  She gave it to Afghanistan. What these people ...     48_2024   \n",
      "\n",
      "                                         dialogue_paths snippet_indexes  \\\n",
      "0     [D:\\newargmining\\testdataset\\MMUSED-fallacy\\au...            [87]   \n",
      "1     [D:\\newargmining\\testdataset\\MMUSED-fallacy\\au...           [149]   \n",
      "2     [D:\\newargmining\\testdataset\\MMUSED-fallacy\\au...           [146]   \n",
      "3     [D:\\newargmining\\testdataset\\MMUSED-fallacy\\au...           [231]   \n",
      "4     [D:\\newargmining\\testdataset\\MMUSED-fallacy\\au...           [297]   \n",
      "...                                                 ...             ...   \n",
      "3383  [D:\\newargmining\\testdataset\\MMUSED-fallacy\\au...          [1071]   \n",
      "3384  [D:\\newargmining\\testdataset\\MMUSED-fallacy\\au...          [1072]   \n",
      "3385  [D:\\newargmining\\testdataset\\MMUSED-fallacy\\au...          [1073]   \n",
      "3386  [D:\\newargmining\\testdataset\\MMUSED-fallacy\\au...          [1074]   \n",
      "3387  [D:\\newargmining\\testdataset\\MMUSED-fallacy\\au...          [1075]   \n",
      "\n",
      "                                      snippet_sentences  \\\n",
      "0     [And there are other ways of squeezing this bu...   \n",
      "1     [And you let those people go with the guidelin...   \n",
      "2     [In mine, I happen to believe in the people an...   \n",
      "3     [That's why faith in the United States is pure...   \n",
      "4     [They know that these toxic waste dumps should...   \n",
      "...                                                 ...   \n",
      "3383        [She gave a lot of it away to the Taliban.]   \n",
      "3384                      [She gave it to Afghanistan.]   \n",
      "3385  [What these people have done to our country an...   \n",
      "3386  [Many of them are criminals and they're destro...   \n",
      "3387  [The worst president, the worst vice president...   \n",
      "\n",
      "                                                snippet  \\\n",
      "0     And there are other ways of squeezing this bud...   \n",
      "1     And you let those people go with the guideline...   \n",
      "2     In mine, I happen to believe in the people and...   \n",
      "3     That's why faith in the United States is pure ...   \n",
      "4     They know that these toxic waste dumps should ...   \n",
      "...                                                 ...   \n",
      "3383          She gave a lot of it away to the Taliban.   \n",
      "3384                        She gave it to Afghanistan.   \n",
      "3385  What these people have done to our country and...   \n",
      "3386  Many of them are criminals and they're destroy...   \n",
      "3387  The worst president, the worst vice president ...   \n",
      "\n",
      "                                          snippet_paths fallacy  \n",
      "0     [D:\\newargmining\\testdataset\\MMUSED-fallacy\\au...       0  \n",
      "1     [D:\\newargmining\\testdataset\\MMUSED-fallacy\\au...       0  \n",
      "2     [D:\\newargmining\\testdataset\\MMUSED-fallacy\\au...       1  \n",
      "3     [D:\\newargmining\\testdataset\\MMUSED-fallacy\\au...       0  \n",
      "4     [D:\\newargmining\\testdataset\\MMUSED-fallacy\\au...       0  \n",
      "...                                                 ...     ...  \n",
      "3383  [D:\\newargmining\\testdataset\\MMUSED-fallacy\\au...    None  \n",
      "3384  [D:\\newargmining\\testdataset\\MMUSED-fallacy\\au...    None  \n",
      "3385  [D:\\newargmining\\testdataset\\MMUSED-fallacy\\au...    None  \n",
      "3386  [D:\\newargmining\\testdataset\\MMUSED-fallacy\\au...    None  \n",
      "3387  [D:\\newargmining\\testdataset\\MMUSED-fallacy\\au...    None  \n",
      "\n",
      "[3388 rows x 10 columns]\n",
      "Index(['dialogue_indexes', 'dialogue_sentences', 'dialogue', 'dialogue_id',\n",
      "       'dialogue_paths', 'snippet_indexes', 'snippet_sentences', 'snippet',\n",
      "       'snippet_paths', 'fallacy'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = mm_used_fallacy_loader.data\n",
    "print(f\"Dataset size: {len(df)} samples\")\n",
    "print(df)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CPInS-01\\AppData\\Local\\Temp\\ipykernel_23436\\2655930280.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['fallacy'] = df['fallacy'].astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique dialouges: 37\n",
      "Number of None/NaN values in fallacy column: 2160\n",
      "Dataset size after removing None values: 1228 samples\n",
      "\n",
      "Fallacy class distribution:\n",
      "  Appeal to Emotion: 757 samples (61.6%)\n",
      "  Appeal to Authority: 190 samples (15.5%)\n",
      "  Ad Hominem: 145 samples (11.8%)\n",
      "  False Cause: 56 samples (4.6%)\n",
      "  Slippery Slope: 46 samples (3.7%)\n",
      "  Slogans: 34 samples (2.8%)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Get the data\n",
    "\n",
    "print(f\"Number of unique dialouges: {df['dialogue_id'].nunique()}\")\n",
    "\n",
    "# Remove any None values from the fallacy column\n",
    "print(f\"Number of None/NaN values in fallacy column: {df['fallacy'].isna().sum()}\")\n",
    "df = df.dropna(subset=['fallacy'])\n",
    "print(f\"Dataset size after removing None values: {len(df)} samples\")\n",
    "\n",
    "# Ensure fallacy column is integer type\n",
    "df['fallacy'] = df['fallacy'].astype(int)\n",
    "\n",
    "# Get the class distribution\n",
    "fallacy_counts = df['fallacy'].value_counts().sort_index()\n",
    "print(\"\\nFallacy class distribution:\")\n",
    "for fallacy_id, count in fallacy_counts.items():\n",
    "    print(f\"  {fallacy_mapping[fallacy_id]}: {count} samples ({count/len(df)*100:.1f}%)\")\n",
    "\n",
    "# Visualize fallacy distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(\n",
    "    [fallacy_mapping[i] for i in fallacy_counts.index], \n",
    "    fallacy_counts.values\n",
    ")\n",
    "\n",
    "# Add value labels on top of bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(\n",
    "        bar.get_x() + bar.get_width()/2.,\n",
    "        height + 5,\n",
    "        f'{height}',\n",
    "        ha='center', \n",
    "        va='bottom'\n",
    "    )\n",
    "\n",
    "plt.title('Distribution of Fallacy Classes')\n",
    "plt.xlabel('Fallacy Type')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text label\n",
      "0  And there are other ways of squeezing this bud...     0\n",
      "1  And you let those people go with the guideline...     0\n",
      "2  In mine, I happen to believe in the people and...     1\n",
      "3  That's why faith in the United States is pure ...     0\n",
      "4  They know that these toxic waste dumps should ...     0\n"
     ]
    }
   ],
   "source": [
    "split_info = mm_used_fallacy_loader.get_splits('mm-argfallacy-2025')[0]\n",
    "\n",
    "# Step 3: Convert datasets (UnimodalDataset) to DataFrames\n",
    "def dataset_to_df(dataset):\n",
    "    return pd.DataFrame({\n",
    "        \"text\": dataset.inputs,\n",
    "        \"label\": dataset.labels,\n",
    "    })\n",
    "\n",
    "train_df = dataset_to_df(split_info.train)\n",
    "val_df = dataset_to_df(split_info.val)\n",
    "test_df = dataset_to_df(split_info.test)\n",
    "\n",
    "# Get the first training sample\n",
    "# First 5 samples\n",
    "print(train_df.iloc[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution in Train: Counter({0: 605, 1: 152, 2: 116, 3: 45, 4: 37, 5: 27})\n",
      "Class distribution in Val:   Counter({0: 76, 1: 19, 2: 14, 3: 6, 4: 4, 5: 4})\n",
      "Class distribution in Test:  Counter({0: 76, 1: 19, 2: 15, 3: 5, 4: 5, 5: 3})\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "# First: split into train (80%) and temp (20% for val+test)\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n",
    "    train_df[\"text\"].tolist(),\n",
    "    train_df[\"label\"].tolist(),\n",
    "    test_size=0.2,\n",
    "    random_state=SEED,\n",
    "    stratify=train_df[\"label\"]\n",
    ")\n",
    "\n",
    "# Then: split temp into val (10%) and test (10%)\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
    "    temp_texts,\n",
    "    temp_labels,\n",
    "    test_size=0.5,\n",
    "    random_state=SEED,\n",
    "    stratify=temp_labels\n",
    ")\n",
    "\n",
    "# Print class distributions\n",
    "print(\"Class distribution in Train:\", Counter(train_labels))\n",
    "print(\"Class distribution in Val:  \", Counter(val_labels))\n",
    "print(\"Class distribution in Test: \", Counter(test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 50 Slogans fallacy examples to your dataset\n",
    "slogan_examples = [\n",
    "    \"America deserves better.\",\n",
    "    \"A stronger tomorrow starts today.\",\n",
    "    \"Leadership you can trust.\",\n",
    "    \"Putting people first.\",\n",
    "    \"One nation, one future.\",\n",
    "    \"Change you can believe in.\",\n",
    "    \"Real solutions for real problems.\",\n",
    "    \"Prosperity for all.\",\n",
    "    \"It’s time to take back our country.\",\n",
    "    \"Hope is not a strategy.\",\n",
    "    \"The power of the people is stronger than the people in power.\",\n",
    "    \"A fair shot for every child.\",\n",
    "    \"Faith, family, freedom.\",\n",
    "    \"Because every life counts.\",\n",
    "    \"Secure the border, protect the dream.\",\n",
    "    \"Standing tall for our values.\",\n",
    "    \"Stronger together.\",\n",
    "    \"Power to the people.\",\n",
    "    \"Defend the dream.\",\n",
    "    \"Rebuild. Restore. Renew.\",\n",
    "    \"Opportunity, not oppression.\",\n",
    "    \"Every voice matters.\",\n",
    "    \"Common sense for the common good.\",\n",
    "    \"Bringing America back.\",\n",
    "    \"Keeping the American promise.\",\n",
    "    \"Liberty and justice for all.\",\n",
    "    \"Believe in better.\",\n",
    "    \"Your future. Your choice.\",\n",
    "    \"Take the lead, shape the future.\",\n",
    "    \"Working for you.\",\n",
    "    \"Courage to change.\",\n",
    "    \"For the people, not the powerful.\",\n",
    "    \"Building bridges, not walls.\",\n",
    "    \"Let freedom ring.\",\n",
    "    \"This is our moment.\",\n",
    "    \"America first, always.\",\n",
    "    \"Strong families. Strong country.\",\n",
    "    \"Our future is worth fighting for.\",\n",
    "    \"More jobs, less government.\",\n",
    "    \"Together, we rise.\",\n",
    "    \"The right choice for real change.\",\n",
    "    \"Jobs. Freedom. Security.\",\n",
    "    \"New energy for a new era.\",\n",
    "    \"Your voice. Your vote.\",\n",
    "    \"No more politics as usual.\",\n",
    "    \"We fight for truth.\",\n",
    "    \"A stronger America starts here.\",\n",
    "    \"From many, one.\",\n",
    "    \"No excuses. Just results.\",\n",
    "    \"Rise up for what's right.\"\n",
    "]\n",
    "new_labels = [5] * len(slogan_examples)\n",
    "\n",
    "# Add to existing arrays\n",
    "train_texts.extend(slogan_examples)\n",
    "train_labels.extend(new_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Updated train_texts: 1062 entries\n",
      "✅ Updated train_labels: 1062 entries\n"
     ]
    }
   ],
   "source": [
    "# 1. Augmented slogans (label 5 = \"Slogans\")\n",
    "new_slogans = [\n",
    "    \"Together, we can do the impossible.\",\n",
    "    \"This is not just a policy, it's a promise.\",\n",
    "    \"America deserves better.\",\n",
    "    \"Believe in the dream, achieve the impossible.\",\n",
    "    \"Let the change begin today.\",\n",
    "    \"Justice will prevail, always.\",\n",
    "    \"Our future is now.\",\n",
    "    \"We stand strong, we stand united.\",\n",
    "    \"Hope. Progress. Victory.\",\n",
    "    \"A better tomorrow starts with us.\",\n",
    "    \"In unity, we find strength.\",\n",
    "    \"This is the dawn of a new era.\",\n",
    "    \"It's not just politics, it's personal.\",\n",
    "    \"Because your voice matters.\",\n",
    "    \"The will of the people cannot be ignored.\",\n",
    "    \"No more excuses. It's time to act.\",\n",
    "    \"Power to the people.\",\n",
    "    \"For the many, not the few.\",\n",
    "    \"Let's take back our future.\",\n",
    "    \"Courage. Character. Commitment.\",\n",
    "    \"A vision for every generation.\",\n",
    "    \"The heart of the nation beats stronger together.\",\n",
    "    \"Freedom isn't free, but it's worth fighting for.\",\n",
    "    \"One country. One destiny.\",\n",
    "    \"It’s not about left or right, it’s about moving forward.\",\n",
    "    \"Stronger families, stronger nation.\",\n",
    "    \"Lead with hope, not fear.\",\n",
    "    \"We are the change we've been waiting for.\",\n",
    "    \"Truth. Trust. Transformation.\",\n",
    "    \"Your dreams are our mission.\"\n",
    "]\n",
    "\n",
    "new_labels = [5] * len(new_slogans)\n",
    "\n",
    "# Add to existing arrays\n",
    "train_texts.extend(new_slogans)\n",
    "train_labels.extend(new_labels)\n",
    "\n",
    "print(f\"✅ Updated train_texts: {len(train_texts)} entries\")\n",
    "print(f\"✅ Updated train_labels: {len(train_labels)} entries\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ad_hominem_examples = [\n",
    "#     \"My opponent can't possibly make good decisions about the economy; he has filed for bankruptcy before.\",\n",
    "#     \"Why should we listen to the coach's strategy? He was never even a good player!\",\n",
    "#     \"You can't talk about conservation if you're not a vegan.\",\n",
    "#     \"Your opinion on the matter doesn't count; you only have 50 followers.\",\n",
    "#     \"Why should we listen to your ideas for the group project? You got a C on the last assignment.\",\n",
    "#     \"You're not a good Christian, so your points about morality are invalid.\",\n",
    "#     \"We shouldn't take her suggestions seriously. She's new here.\",\n",
    "#     \"How can you give me health advice? You're overweight.\",\n",
    "#     \"He doesn't have a Ph.D., so his findings on climate change are worthless.\",\n",
    "#     \"He can't be a good musician; he was trained as an engineer.\",\n",
    "#     \"Her movie reviews can't be trusted; she liked that film everyone hates.\",\n",
    "#     \"You didn't even finish high school, so what would you know about literature?\",\n",
    "#     \"You own a leather jacket, so you can't argue for animal rights.\",\n",
    "#     \"A man can't have an opinion on women's rights.\",\n",
    "#     \"He's single; what does he know about relationships?\",\n",
    "#     \"You don't have kids, so your ideas about parenting are irrelevant.\",\n",
    "#     \"She's old, so what would she know about smartphones?\",\n",
    "#     \"He's not even a lawyer; why would we listen to him about the legal system?\",\n",
    "#     \"He dropped out of college, so he can't be trusted to talk about history.\",\n",
    "#     \"How can you support environmentalism when you drive an SUV?\",\n",
    "#     \"Woody Allen's films are terrible because his adopted daughter accused him of abuse.\",\n",
    "#     \"You must be gay or lesbian because you support gay marriage.\",\n",
    "#     \"You're not African-American, so you have no right to have an opinion about #BlackLivesMatter.\",\n",
    "#     \"Are you sure you didn't consent to have sex with Mr. Hadley? You were dressed very provocatively that night.\",\n",
    "#     \"Bill claims that this was an accident, but we know Bill to be a liar, so we can't take his word for it.\",\n",
    "#     \"Susan is an avid hunter; therefore, she cannot possibly support gun control.\",\n",
    "#     \"Alex: I think we should increase federal spending on education. Bob: You're a fascist, so clearly we shouldn't listen to what you have to say about education.\",\n",
    "#     \"Alex: I think we should increase federal spending on education. Bob: You're only saying that because you want to show support for the president you voted for.\",\n",
    "#     \"Alex: I think we should increase federal spending on education. Bob: You clearly don't even care about public education since you sent your own kids to a private school.\",\n",
    "#     \"Alex: I think we should increase federal spending on education. Bob: Well, the Nazis also thought that, so you're like the Nazis.\",\n",
    "#     \"Alex: I think that as a country, we're not spending enough on education. Bob: Well, if you don't like it here, then you should just leave and go somewhere where they have the kind of education that you want.\",\n",
    "#     \"Alex: I think we should increase federal spending on education. Bob: Okay, okay, no need to get so worked up over these things.\",\n",
    "#     \"You're clearly too young to understand the importance of tradition.\",\n",
    "#     \"You don’t understand marriage—you're divorced.\",\n",
    "#     \"You’re not a patriot because you criticize the government.\",\n",
    "#     \"You’re only supporting that policy because your dad is rich.\",\n",
    "#     \"You're saying that because you're just a bleeding-heart liberal.\",\n",
    "#     \"You can't possibly understand poverty—you grew up wealthy.\",\n",
    "#     \"Why are you lecturing me on mental health when you're clearly unstable?\",\n",
    "#     \"Oh please, you only care about the environment when it’s convenient for you.\",\n",
    "#     \"He’s just a keyboard warrior, ignore his opinion.\",\n",
    "#     \"You're not a scientist, so your view on COVID is irrelevant.\",\n",
    "#     \"She's always been emotional—no surprise she's against this policy.\",\n",
    "#     \"Don’t listen to him; he got fired from his last job.\",\n",
    "#     \"He’s a known atheist, of course he doesn't care about family values.\",\n",
    "#     \"She only supports that movement because she's trying to be trendy.\",\n",
    "#     \"You were in jail once—your thoughts on prison reform are biased.\",\n",
    "#     \"You cheated in college, so don’t talk about academic honesty.\",\n",
    "#     \"You used to smoke; your argument against cigarettes is hypocritical.\",\n",
    "#     \"That guy lives in his mom’s basement; why would we listen to him?\",\n",
    "#     \"He’s just doing this to get attention, not because he believes it.\",\n",
    "# ]\n",
    "# # Add label 2 for Ad Hominem\n",
    "# new_labels_ad_hominem = [2] * len(ad_hominem_examples)\n",
    "\n",
    "# # Append to training data\n",
    "# train_texts.extend(ad_hominem_examples)\n",
    "# train_labels.extend(new_labels_ad_hominem)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 50 examples of False Cause fallacies (text + label)\n",
    "false_cause_examples = [\n",
    "    \"Ever since we started the new recycling program, the local crime rate has dropped. Clearly, recycling makes our city safer.\",\n",
    "    \"The economy improved after I started wearing my lucky tie to work. That tie must be good luck.\",\n",
    "    \"Sales have gone up since we painted the office walls blue. The color must be making employees more productive.\",\n",
    "    \"After we hired a new janitor, employee satisfaction increased. He must be the reason for happier workers.\",\n",
    "    \"Since switching to biodegradable cups, customer complaints have decreased. The cups must be the reason.\",\n",
    "    \"Once we installed solar panels, our employee turnover dropped. Clearly, green energy keeps people around.\",\n",
    "    \"Since I got my promotion, traffic on my commute has improved. I must be lucky for the city.\",\n",
    "    \"After we introduced free coffee, our tech systems have crashed less often. Coffee must boost server stability.\",\n",
    "    \"We passed a new dress code and productivity went up. The dress code clearly caused it.\",\n",
    "    \"Since we started giving out bonuses, flu cases have decreased. Bonuses must improve health.\",\n",
    "    \"After the mayor took office, the sports team started winning. The mayor is clearly bringing good luck.\",\n",
    "    \"Once we stopped printing memos, office fires declined. Memos were clearly a fire hazard.\",\n",
    "    \"Ever since we bought ergonomic chairs, fewer people are late. The chairs must boost punctuality.\",\n",
    "    \"Since we added a foosball table to the break room, profits rose. It's working!\",\n",
    "    \"The budget improved after we fired our receptionist. She must have been draining the economy.\",\n",
    "    \"We changed our logo and our stock prices climbed. That design must be magic.\",\n",
    "    \"After launching the new app, winter was milder. The app is saving the planet!\",\n",
    "    \"Crime increased right after that movie was released. The movie must be to blame.\",\n",
    "    \"After that senator took office, gas prices skyrocketed. Coincidence? I think not.\",\n",
    "    \"We passed a sugar tax and car accidents declined. Clearly, taxing sugar saves lives.\",\n",
    "    \"The national anthem was changed, and inflation went down. The anthem must have economic power.\",\n",
    "    \"After cutting library hours, unemployment decreased. Maybe people are working instead of reading.\",\n",
    "    \"We upgraded the cafeteria menu, and national test scores improved. Healthy food is the key.\",\n",
    "    \"Once we banned plastic straws, graduation rates went up. Plastic straws must hinder education.\",\n",
    "    \"Since we held a wellness seminar, no earthquakes have hit. We're clearly preventing disasters.\",\n",
    "    \"We implemented a new HR policy, and a rival company went bankrupt. Our policy is too strong!\",\n",
    "    \"After installing speed bumps, local students started scoring higher in math. Coincidence? Doubtful.\",\n",
    "    \"We added a diversity workshop, and quarterly revenue increased. Inclusion drives income.\",\n",
    "    \"The government changed its flag, and wildfires decreased. Symbolism must work.\",\n",
    "    \"Since we promoted remote work, rainfall has been lighter. Telecommuting affects weather now?\",\n",
    "    \"A new textbook was released, and power outages became less frequent. Must be an enlightened grid.\",\n",
    "    \"We introduced dress-down Fridays, and energy bills dropped. Jeans are energy efficient.\",\n",
    "    \"After increasing vacation days, fewer natural disasters were reported. Rest must balance nature.\",\n",
    "    \"Since we banned soda in schools, the GDP grew. Bubbly drinks were holding us back.\",\n",
    "    \"After closing several libraries, test scores went up. Maybe less reading helps students focus.\",\n",
    "    \"The President started jogging every morning, and the stock market surged. Fitness fuels finance.\",\n",
    "    \"Once the national bird was changed, exports increased. A bird-brained economic boom.\",\n",
    "    \"After canceling a TV show, crime rates declined. That show was clearly a bad influence.\",\n",
    "    \"They installed new streetlights, and divorce rates dropped. Lighting saves marriages.\",\n",
    "    \"After introducing electric buses, public speeches became more passionate. Electric energy, literally.\",\n",
    "    \"Since the policy change, wild animal sightings have decreased. Government efficiency at work!\",\n",
    "    \"We upgraded the website and the birth rate increased. A modern design is irresistible.\",\n",
    "    \"After banning plastic bags, rainfall increased. Nature is grateful.\",\n",
    "    \"We added more bike lanes, and the literacy rate went up. Bikes and books go hand in hand.\",\n",
    "    \"Since changing the national anthem tempo, forest fires have dropped. Rhythm restores nature.\",\n",
    "    \"Ever since switching fonts in the constitution, fewer people have moved abroad. Typography matters.\",\n",
    "    \"After approving a new textbook, average sleep quality improved. Knowledge brings rest.\",\n",
    "    \"They cleaned a river last month, and new startups emerged. Clean water, clean innovation.\",\n",
    "    \"After switching government email servers, the ozone layer improved. Digital change saves Earth.\",\n",
    "    \"Since adopting the new anthem, fewer volcanoes have erupted. It’s that powerful.\",\n",
    "    \"Ever since the prime minister changed their hairstyle, unemployment dropped. Good hair, good economy.\"\n",
    "]\n",
    "# Add label 2 for Ad Hominem\n",
    "new_labelsfalse_cause_examples = [3] * len(false_cause_examples)\n",
    "\n",
    "# Append to training data\n",
    "train_texts.extend(false_cause_examples)\n",
    "train_labels.extend(new_labelsfalse_cause_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_slippery_slope_examples = [\n",
    "    \"If we allow students to redo assignments, soon they’ll expect to retake entire courses.\",\n",
    "    \"If we legalize marijuana, next we’ll be legalizing all drugs.\",\n",
    "    \"Allowing one exception to the rule means soon there will be no rules at all.\",\n",
    "    \"If we raise taxes on the rich, soon no one will want to work hard.\",\n",
    "    \"If we allow one statue to be taken down, they’ll want to erase all of history.\",\n",
    "    \"If we let one child skip the vaccine, disease will spread uncontrollably.\",\n",
    "    \"If we don’t discipline this employee, the whole team will become lazy.\",\n",
    "    \"If we pass this law, it will open the floodgates to government overreach.\",\n",
    "    \"Letting them protest now will lead to total social unrest.\",\n",
    "    \"If we ban sugary drinks, next they'll ban fast food entirely.\",\n",
    "    \"If we allow online voting, next we’ll eliminate in-person voting altogether.\",\n",
    "    \"If we allow this book in schools, soon we’ll be teaching dangerous ideologies.\",\n",
    "    \"If we tolerate this kind of speech, hate will spread everywhere.\",\n",
    "    \"If we give this group special rights, everyone will demand them.\",\n",
    "    \"If we don't punish this behavior harshly, crime will skyrocket.\",\n",
    "    \"If we let them build a mall here, it’ll destroy the whole community.\",\n",
    "    \"If we approve this spending, we'll go bankrupt as a nation.\",\n",
    "    \"If we let kids use calculators, they’ll forget how to do math.\",\n",
    "    \"If we let them skip one homework, they’ll never do homework again.\",\n",
    "    \"If we allow people to work remotely, no one will come to the office.\",\n",
    "    \"If we let one religious group display symbols, every group will demand equal space.\",\n",
    "    \"If we increase minimum wage, companies will fire workers and automate everything.\",\n",
    "    \"If we forgive one debt, everyone will want their debts erased.\",\n",
    "    \"If we open our borders slightly, we'll have no control over immigration.\",\n",
    "    \"If we fund this art project, we'll be forced to fund every controversial piece.\",\n",
    "    \"If we allow pets in the office, next we’ll be running a zoo.\",\n",
    "    \"If we let people work 4-day weeks, productivity will collapse.\",\n",
    "    \"If we allow this startup to compete, monopolies will fall and chaos will ensue.\",\n",
    "    \"If we stop using fossil fuels, our entire economy will collapse.\",\n",
    "    \"If we don’t regulate AI now, robots will take over society.\",\n",
    "    \"If we pass this healthcare bill, soon we’ll have full-blown socialism.\",\n",
    "    \"If we elect this candidate, they’ll ruin the country in four years.\",\n",
    "    \"If we don't act immediately, climate change will destroy all life.\",\n",
    "    \"If we allow phone use in class, students won’t pay attention ever again.\",\n",
    "    \"If we allow this trend to continue, traditional values will vanish completely.\",\n",
    "    \"If we accept late applications, we’ll lose all control of deadlines.\",\n",
    "    \"If we compromise on this issue, we’ll have to compromise on everything.\",\n",
    "    \"If we allow self-driving cars, human drivers will become obsolete.\",\n",
    "    \"If we don’t arrest this protestor, society will break down.\",\n",
    "    \"If we let them rewrite the curriculum, they’ll rewrite history.\",\n",
    "    \"If we allow one gun regulation, it’s the start of gun confiscation.\",\n",
    "    \"If we give in to this demand, they’ll never stop asking for more.\",\n",
    "    \"If we let this policy pass, every state will have to follow suit.\",\n",
    "    \"If we remove this restriction, people will abuse the system.\",\n",
    "    \"If we stop checking IDs at the door, anyone could sneak in.\",\n",
    "    \"If we let her skip a grade, all parents will demand it for their kids.\",\n",
    "    \"If we allow animal rights to dictate policy, we’ll all be vegans by law.\",\n",
    "    \"If we let robots teach, human teachers will lose their jobs.\",\n",
    "    \"If we approve this merger, soon all companies will consolidate into one.\",\n",
    "    \"If we let one criminal go free, justice will lose all meaning.\"\n",
    "]\n",
    "new_labels = [4] * len(new_slippery_slope_examples)\n",
    "train_texts.extend(new_slippery_slope_examples)\n",
    "train_labels.extend(new_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 52 new Ad Hominem examples.\n",
      "Total training samples now: 1215\n"
     ]
    }
   ],
   "source": [
    "ad_hominem_examples = [\n",
    "    \"My opponent's stance on healthcare is irrelevant; remember, he was caught lying about his education.\",\n",
    "    \"She advocates for environmental policies, but she flies on private jets regularly.\",\n",
    "    \"Don't trust his economic plan; he filed for bankruptcy twice.\",\n",
    "    \"He talks about family values, yet he's been divorced three times.\",\n",
    "    \"Her opinion on education reform shouldn't matter; she never attended public school.\",\n",
    "    \"He supports tax increases, but he was caught evading taxes last year.\",\n",
    "    \"Why listen to her on military matters? She never served a day in the armed forces.\",\n",
    "    \"He can't be serious about healthcare; he's overweight and out of shape.\",\n",
    "    \"She argues for gun control, but she owns multiple firearms herself.\",\n",
    "    \"His views on immigration are invalid; he's the child of immigrants.\",\n",
    "    \"She promotes women's rights, but she once made sexist remarks herself.\",\n",
    "    \"Don't take his climate change arguments seriously; he drives a gas-guzzling SUV.\",\n",
    "    \"He talks about honesty in politics, yet he was involved in a plagiarism scandal.\",\n",
    "    \"Her stance on education is flawed; she was a terrible student.\",\n",
    "    \"He supports welfare programs, but he comes from a wealthy family.\",\n",
    "    \"She criticizes corporate greed, but she owns significant stock in major corporations.\",\n",
    "    \"His foreign policy ideas are naive; he has no international experience.\",\n",
    "    \"She advocates for LGBTQ+ rights, but she once opposed same-sex marriage.\",\n",
    "    \"Don't believe his fiscal responsibility talk; he mismanaged his own company's finances.\",\n",
    "    \"She speaks on public health, but she refuses to vaccinate her children.\",\n",
    "    \"He promotes transparency, yet he deleted thousands of his emails.\",\n",
    "    \"Her views on policing are biased; her brother is a police officer.\",\n",
    "    \"He argues for prison reform, but he has a criminal record himself.\",\n",
    "    \"She supports freedom of speech, but she once tried to censor a journalist.\",\n",
    "    \"His environmental policies can't be trusted; he invested in oil companies.\",\n",
    "    \"She talks about affordable housing, but she owns multiple luxury apartments.\",\n",
    "    \"He advocates for student loan forgiveness, yet he paid off his loans early.\",\n",
    "    \"She supports labor unions, but she laid off workers without notice.\",\n",
    "    \"His healthcare plan is questionable; he has no medical background.\",\n",
    "    \"She criticizes government spending, but she approved a costly project.\",\n",
    "    \"He talks about unity, yet he made divisive comments in the past.\",\n",
    "    \"Her stance on drug policy is invalid; she admitted to past drug use.\",\n",
    "    \"He promotes digital privacy, but he was involved in a data breach scandal.\",\n",
    "    \"She supports veterans, but she voted against veteran benefits.\",\n",
    "    \"His education policy is flawed; he dropped out of college.\",\n",
    "    \"She talks about ethics, yet she accepted gifts from lobbyists.\",\n",
    "    \"He advocates for public transportation, but he commutes by helicopter.\",\n",
    "    \"She supports small businesses, but she sued a local shop over a minor issue.\",\n",
    "    \"His views on taxation are hypocritical; he keeps his money in offshore accounts.\",\n",
    "    \"She promotes healthy eating, but she owns a fast-food franchise.\",\n",
    "    \"He talks about national security, yet he leaked confidential information.\",\n",
    "    \"She supports arts funding, but she cut the budget for local theaters.\",\n",
    "    \"His stance on agriculture is questionable; he has never visited a farm.\",\n",
    "    \"She advocates for mental health, but she mocked a colleague's therapy sessions.\",\n",
    "    \"He supports police reform, but he once called for harsher penalties.\",\n",
    "    \"She talks about internet freedom, yet she supported censorship laws.\",\n",
    "    \"His views on housing are invalid; he lives in a mansion.\",\n",
    "    \"She promotes education, but she sends her children to private schools.\",\n",
    "    \"He supports renewable energy, but he invested in coal companies.\",\n",
    "    \"She talks about public service, yet she missed numerous council meetings.\",\n",
    "    \"His stance on youth programs is flawed; he has no children.\",\n",
    "    \"She advocates for animal rights, but she wears fur coats.\",\n",
    "]\n",
    "# Assuming Ad Hominem has label 2 in your dataset\n",
    "new_labels = [2] * len(ad_hominem_examples)\n",
    "\n",
    "# Append the new examples to your training data\n",
    "train_texts.extend(ad_hominem_examples)\n",
    "train_labels.extend(new_labels)\n",
    "\n",
    "print(f\"Added {len(ad_hominem_examples)} new Ad Hominem examples.\")\n",
    "print(f\"Total training samples now: {len(train_texts)}\")\n",
    "# new_ad_hominem = [\n",
    "#     \"Of course he supports that policy — he's never had to work a real job in his life.\",\n",
    "#     \"I wouldn't trust her opinion on healthcare; she can’t even take care of her own family.\",\n",
    "#     \"You’re going to believe someone who lied about their college degree?\",\n",
    "#     \"Naturally, he opposes tax reform — he’s been evading taxes for years.\",\n",
    "#     \"She’s criticizing our economic plan, but her company went bankrupt twice.\",\n",
    "#     \"That’s coming from someone who’s never served their country a day in their life.\",\n",
    "#     \"Only a hypocrite like him would pretend to care about the environment while flying private jets.\",\n",
    "#     \"Before we even listen to him, remember he was caught plagiarizing his speech last year.\",\n",
    "#     \"She claims to care about education, but her record shows she cut school funding repeatedly.\",\n",
    "#     \"How can you trust a man who can’t stay loyal to his own spouse?\",\n",
    "#     \"He wants to lead the country? He can’t even manage his own finances.\",\n",
    "#     \"That argument is weak, especially coming from someone who failed their last three campaigns.\",\n",
    "#     \"We shouldn’t listen to her; she flip-flops constantly.\",\n",
    "#     \"Why would we take advice from someone who’s been under ethics investigation multiple times?\",\n",
    "#     \"Let’s not forget, the last time he was in charge, there were multiple corruption scandals.\"\n",
    "# ]\n",
    "\n",
    "# new_labels_ad_hominem = [2] * len(new_ad_hominem)\n",
    "\n",
    "# train_texts.extend(new_ad_hominem)\n",
    "# train_labels.extend(new_labels_ad_hominem)\n",
    "\n",
    "# print(\"Added\", len(new_ad_hominem), \"new Ad Hominem examples.\")\n",
    "# print(\"Total training samples now:\", len(train_texts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 233 augmented examples to augmented_fallacy_examples.csv\n",
      "\n",
      "Augmented examples summary:\n",
      "            label  count\n",
      "0      Ad Hominem     52\n",
      "1     False Cause     51\n",
      "2  Slippery Slope     50\n",
      "3         Slogans     80\n"
     ]
    }
   ],
   "source": [
    "# Create a combined DataFrame with all the augmented examples and original data\n",
    "import pandas as pd\n",
    "\n",
    "# Collect all augmented examples\n",
    "augmented_data = []\n",
    "\n",
    "# Original slogans\n",
    "for text, label in zip(slogan_examples, [5] * len(slogan_examples)):\n",
    "    augmented_data.append({\n",
    "        \"text\": text,\n",
    "        \"label\": fallacy_mapping[5]\n",
    "    })\n",
    "\n",
    "# New slogans\n",
    "for text, label in zip(new_slogans, [5] * len(new_slogans)):\n",
    "    augmented_data.append({\n",
    "        \"text\": text,\n",
    "        \"label\": fallacy_mapping[5]\n",
    "    })\n",
    "\n",
    "# False Cause examples\n",
    "for text, label in zip(false_cause_examples, [3] * len(false_cause_examples)):\n",
    "    augmented_data.append({\n",
    "        \"text\": text,\n",
    "        \"label\": fallacy_mapping[3]\n",
    "    })\n",
    "\n",
    "# Slippery Slope examples\n",
    "for text, label in zip(new_slippery_slope_examples, [4] * len(new_slippery_slope_examples)):\n",
    "    augmented_data.append({\n",
    "        \"text\": text,\n",
    "        \"label\": fallacy_mapping[4]\n",
    "    })\n",
    "\n",
    "# Ad Hominem examples\n",
    "for text, label in zip(ad_hominem_examples, [2] * len(ad_hominem_examples)):\n",
    "    augmented_data.append({\n",
    "        \"text\": text,\n",
    "        \"label\": fallacy_mapping[2]\n",
    "    })\n",
    "\n",
    "# Create DataFrame from all augmented examples\n",
    "augmented_df = pd.DataFrame(augmented_data)\n",
    "\n",
    "# Save to CSV\n",
    "csv_path = \"augmented_fallacy_examples.csv\"\n",
    "augmented_df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"Saved {len(augmented_df)} augmented examples to {csv_path}\")\n",
    "\n",
    "# Display summary of the augmented dataset\n",
    "summary = augmented_df.groupby([\"label\"]).size().reset_index(name=\"count\")\n",
    "print(\"\\nAugmented examples summary:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "\n",
    "def tokenize(texts):\n",
    "    return tokenizer(\n",
    "        texts,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=MAX_TEXT_LEN,\n",
    "        return_tensors=\"pt\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FallacyDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer):\n",
    "        encodings = tokenize(texts)\n",
    "        self.input_ids = encodings[\"input_ids\"]\n",
    "        self.attention_mask = encodings[\"attention_mask\"]\n",
    "        self.labels = torch.tensor(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[idx],\n",
    "            \"attention_mask\": self.attention_mask[idx],\n",
    "            \"labels\": self.labels[idx]\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = FallacyDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = FallacyDataset(val_texts, val_labels, tokenizer)\n",
    "test_dataset = FallacyDataset(test_texts, test_labels, tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=NUM_CLASSES,ignore_mismatched_sizes=True\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: tensor([0.3347, 1.3322, 1.2054, 2.1094, 2.3276, 1.8925], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Get all training labels\n",
    "all_train_labels = train_labels  # already a list\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(all_train_labels),\n",
    "    y=all_train_labels\n",
    ")\n",
    "\n",
    "# Convert to a torch tensor\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "print(\"Class Weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\newargmining\\.venv\\lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW, get_scheduler\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "num_training_steps = EPOCHS * len(train_loader)\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\", optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_epoch(model, data_loader, optimizer, criterion, scheduler):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch in tqdm(data_loader, desc=\"Training\"):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    accuracy = correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "\n",
    "def evaluate(model, data_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            \n",
    "            # Collecting predictions and labels for metrics calculation\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate average loss\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    \n",
    "    # Convert lists to numpy arrays\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    micro_f1 = f1_score(all_labels, all_preds, average='micro')\n",
    "    precision_macro = precision_score(all_labels, all_preds, average='macro')\n",
    "    recall_macro = recall_score(all_labels, all_preds, average='macro')\n",
    "    \n",
    "    # Generate detailed classification report\n",
    "    class_report = classification_report(all_labels, all_preds, digits=4)\n",
    "    \n",
    "    metrics = {\n",
    "        'loss': avg_loss,\n",
    "        'accuracy': accuracy,\n",
    "        'macro_f1': macro_f1,\n",
    "        'micro_f1': micro_f1,\n",
    "        'precision_macro': precision_macro,\n",
    "        'recall_macro': recall_macro,\n",
    "        'classification_report': class_report\n",
    "    }\n",
    "    \n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def evaluate(model, data_loader, criterion, id2label=None):\n",
    "#     model.eval()\n",
    "#     total_loss = 0\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     all_preds = []\n",
    "#     all_labels = []\n",
    "    \n",
    "#     # Initialize counters for each class\n",
    "#     class_counts = {}\n",
    "#     class_correct = {}\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for batch in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "#             input_ids = batch[\"input_ids\"].to(device)\n",
    "#             attention_mask = batch[\"attention_mask\"].to(device)\n",
    "#             labels = batch[\"labels\"].to(device)\n",
    "            \n",
    "#             # Get the original texts for printing\n",
    "#             texts = batch.get(\"texts\", tokenizer.batch_decode(input_ids, skip_special_tokens=True))\n",
    "            \n",
    "#             outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "#             loss = outputs.loss\n",
    "#             logits = outputs.logits\n",
    "            \n",
    "#             total_loss += loss.item()\n",
    "#             preds = torch.argmax(logits, dim=1)\n",
    "#             correct += (preds == labels).sum().item()\n",
    "#             total += labels.size(0)\n",
    "            \n",
    "#             # Print input text, predicted class, and actual class\n",
    "#             for i in range(len(preds)):\n",
    "#                 pred_label = id2label[preds[i].item()] if id2label else preds[i].item()\n",
    "#                 true_label = id2label[labels[i].item()] if id2label else labels[i].item()\n",
    "#                 text = texts[i] if isinstance(texts, list) else texts\n",
    "                \n",
    "#                 # Count for class statistics\n",
    "#                 true_class = labels[i].item()\n",
    "#                 if true_class not in class_counts:\n",
    "#                     class_counts[true_class] = 0\n",
    "#                     class_correct[true_class] = 0\n",
    "#                 class_counts[true_class] += 1\n",
    "#                 if preds[i].item() == true_class:\n",
    "#                     class_correct[true_class] += 1\n",
    "                \n",
    "#                 print(f\"Text: {text[:100]}{'...' if len(text) > 100 else ''}\")\n",
    "#                 print(f\"Predicted: {pred_label}, Actual: {true_label}\")\n",
    "#                 print(\"-\" * 50)\n",
    "            \n",
    "#             # Store predictions and labels for metrics\n",
    "#             all_preds.extend(preds.cpu().numpy())\n",
    "#             all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "#     # Print class-wise statistics\n",
    "#     print(\"\\n--- Class Statistics ---\")\n",
    "#     for class_id in sorted(class_counts.keys()):\n",
    "#         class_name = id2label[class_id] if id2label else f\"Class {class_id}\"\n",
    "#         class_accuracy = class_correct[class_id] / class_counts[class_id] if class_counts[class_id] > 0 else 0\n",
    "#         print(f\"{class_name}: {class_correct[class_id]}/{class_counts[class_id]} correct ({class_accuracy:.2%})\")\n",
    "    \n",
    "#     print(f\"\\nTotal samples: {total}\")\n",
    "#     print(f\"Total correct: {correct}\")\n",
    "#     print(f\"Overall accuracy: {correct/total:.2%}\")\n",
    "\n",
    "#     avg_loss = total_loss / len(data_loader)\n",
    "#     accuracy = correct / total\n",
    "#     return avg_loss, accuracy, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lr= 2e5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🌟 Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:17<00:00,  4.43it/s]\n",
      "Evaluating: 100%|██████████| 76/76 [00:04<00:00, 16.32it/s]\n",
      "d:\\newargmining\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\newargmining\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\newargmining\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\newargmining\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1689\n",
      "Train Accuracy: 0.5506\n",
      "Train Macro F1: 0.2079\n",
      "Train Micro F1: 0.5506\n",
      "Train Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5256    1.0000    0.6891       605\n",
      "           1     1.0000    0.0066    0.0131       152\n",
      "           2     1.0000    0.3750    0.5455       168\n",
      "           3     0.0000    0.0000    0.0000        96\n",
      "           4     0.0000    0.0000    0.0000        87\n",
      "           5     0.0000    0.0000    0.0000       107\n",
      "\n",
      "    accuracy                         0.5506      1215\n",
      "   macro avg     0.4209    0.2303    0.2079      1215\n",
      "weighted avg     0.5251    0.5506    0.4202      1215\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 8/8 [00:00<00:00, 16.89it/s]\n",
      "d:\\newargmining\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\newargmining\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\newargmining\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\newargmining\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.1637\n",
      "Accuracy: 0.6260\n",
      "Macro F1: 0.1502\n",
      "Micro F1: 0.6260\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6230    1.0000    0.7677        76\n",
      "           1     0.0000    0.0000    0.0000        19\n",
      "           2     1.0000    0.0714    0.1333        14\n",
      "           3     0.0000    0.0000    0.0000         6\n",
      "           4     0.0000    0.0000    0.0000         4\n",
      "           5     0.0000    0.0000    0.0000         4\n",
      "\n",
      "    accuracy                         0.6260       123\n",
      "   macro avg     0.2705    0.1786    0.1502       123\n",
      "weighted avg     0.4987    0.6260    0.4895       123\n",
      "\n",
      "\n",
      "🌟 Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:16<00:00,  4.49it/s]\n",
      "Evaluating: 100%|██████████| 76/76 [00:04<00:00, 16.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5029\n",
      "Train Accuracy: 0.8527\n",
      "Train Macro F1: 0.8374\n",
      "Train Micro F1: 0.8527\n",
      "Train Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8480    0.9405    0.8918       605\n",
      "           1     0.6619    0.6053    0.6323       152\n",
      "           2     0.8859    0.7857    0.8328       168\n",
      "           3     0.9630    0.8125    0.8814        96\n",
      "           4     0.8929    0.8621    0.8772        87\n",
      "           5     0.9890    0.8411    0.9091       107\n",
      "\n",
      "    accuracy                         0.8527      1215\n",
      "   macro avg     0.8734    0.8079    0.8374      1215\n",
      "weighted avg     0.8547    0.8527    0.8509      1215\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 8/8 [00:00<00:00, 16.78it/s]\n",
      "d:\\newargmining\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\newargmining\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\newargmining\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\newargmining\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.8867\n",
      "Accuracy: 0.6585\n",
      "Macro F1: 0.4728\n",
      "Micro F1: 0.6585\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7159    0.8289    0.7683        76\n",
      "           1     0.4211    0.4211    0.4211        19\n",
      "           2     0.5714    0.2857    0.3810        14\n",
      "           3     0.7500    0.5000    0.6000         6\n",
      "           4     0.6000    0.7500    0.6667         4\n",
      "           5     0.0000    0.0000    0.0000         4\n",
      "\n",
      "    accuracy                         0.6585       123\n",
      "   macro avg     0.5097    0.4643    0.4728       123\n",
      "weighted avg     0.6285    0.6585    0.6341       123\n",
      "\n",
      "\n",
      "🌟 Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:17<00:00,  4.47it/s]\n",
      "Evaluating: 100%|██████████| 76/76 [00:04<00:00, 16.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2948\n",
      "Train Accuracy: 0.9160\n",
      "Train Macro F1: 0.9090\n",
      "Train Micro F1: 0.9160\n",
      "Train Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9525    0.9289    0.9406       605\n",
      "           1     0.7571    0.8816    0.8146       152\n",
      "           2     0.8674    0.9345    0.8997       168\n",
      "           3     0.9556    0.8958    0.9247        96\n",
      "           4     0.9630    0.8966    0.9286        87\n",
      "           5     1.0000    0.8972    0.9458       107\n",
      "\n",
      "    accuracy                         0.9160      1215\n",
      "   macro avg     0.9159    0.9058    0.9090      1215\n",
      "weighted avg     0.9215    0.9160    0.9175      1215\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 8/8 [00:00<00:00, 16.73it/s]\n",
      "d:\\newargmining\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\newargmining\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\newargmining\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\newargmining\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.9401\n",
      "Accuracy: 0.6585\n",
      "Macro F1: 0.5253\n",
      "Micro F1: 0.6585\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7639    0.7237    0.7432        76\n",
      "           1     0.4194    0.6842    0.5200        19\n",
      "           2     0.5833    0.5000    0.5385        14\n",
      "           3     0.7500    0.5000    0.6000         6\n",
      "           4     0.7500    0.7500    0.7500         4\n",
      "           5     0.0000    0.0000    0.0000         4\n",
      "\n",
      "    accuracy                         0.6585       123\n",
      "   macro avg     0.5444    0.5263    0.5253       123\n",
      "weighted avg     0.6641    0.6585    0.6545       123\n",
      "\n",
      "\n",
      "🌟 Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:17<00:00,  4.46it/s]\n",
      "Evaluating: 100%|██████████| 76/76 [00:04<00:00, 16.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1719\n",
      "Train Accuracy: 0.9457\n",
      "Train Macro F1: 0.9407\n",
      "Train Micro F1: 0.9457\n",
      "Train Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9810    0.9405    0.9603       605\n",
      "           1     0.8276    0.9474    0.8834       152\n",
      "           2     0.9111    0.9762    0.9425       168\n",
      "           3     0.9192    0.9479    0.9333        96\n",
      "           4     0.9878    0.9310    0.9586        87\n",
      "           5     1.0000    0.9346    0.9662       107\n",
      "\n",
      "    accuracy                         0.9457      1215\n",
      "   macro avg     0.9378    0.9463    0.9407      1215\n",
      "weighted avg     0.9494    0.9457    0.9465      1215\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 8/8 [00:00<00:00, 16.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.1335\n",
      "Accuracy: 0.6098\n",
      "Macro F1: 0.5026\n",
      "Micro F1: 0.6098\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7869    0.6316    0.7007        76\n",
      "           1     0.4333    0.6842    0.5306        19\n",
      "           2     0.4667    0.5000    0.4828        14\n",
      "           3     0.3333    0.6667    0.4444         6\n",
      "           4     1.0000    0.7500    0.8571         4\n",
      "           5     0.0000    0.0000    0.0000         4\n",
      "\n",
      "    accuracy                         0.6098       123\n",
      "   macro avg     0.5034    0.5387    0.5026       123\n",
      "weighted avg     0.6550    0.6098    0.6194       123\n",
      "\n",
      "\n",
      "🌟 Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:17<00:00,  4.45it/s]\n",
      "Evaluating: 100%|██████████| 76/76 [00:04<00:00, 16.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0819\n",
      "Train Accuracy: 0.9827\n",
      "Train Macro F1: 0.9772\n",
      "Train Micro F1: 0.9827\n",
      "Train Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9868    0.9917    0.9893       605\n",
      "           1     0.9932    0.9671    0.9800       152\n",
      "           2     0.9600    1.0000    0.9796       168\n",
      "           3     0.9789    0.9688    0.9738        96\n",
      "           4     0.9651    0.9540    0.9595        87\n",
      "           5     1.0000    0.9626    0.9810       107\n",
      "\n",
      "    accuracy                         0.9827      1215\n",
      "   macro avg     0.9807    0.9740    0.9772      1215\n",
      "weighted avg     0.9829    0.9827    0.9827      1215\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 8/8 [00:00<00:00, 16.52it/s]\n",
      "d:\\newargmining\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\newargmining\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\newargmining\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\newargmining\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.0708\n",
      "Accuracy: 0.6585\n",
      "Macro F1: 0.4775\n",
      "Micro F1: 0.6585\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7808    0.7500    0.7651        76\n",
      "           1     0.4615    0.6316    0.5333        19\n",
      "           2     0.5000    0.4286    0.4615        14\n",
      "           3     0.4444    0.6667    0.5333         6\n",
      "           4     0.6667    0.5000    0.5714         4\n",
      "           5     0.0000    0.0000    0.0000         4\n",
      "\n",
      "    accuracy                         0.6585       123\n",
      "   macro avg     0.4756    0.4961    0.4775       123\n",
      "weighted avg     0.6540    0.6585    0.6523       123\n",
      "\n",
      "\n",
      "🌟 Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:17<00:00,  4.45it/s]\n",
      "Evaluating: 100%|██████████| 76/76 [00:04<00:00, 16.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0549\n",
      "Train Accuracy: 0.9877\n",
      "Train Macro F1: 0.9847\n",
      "Train Micro F1: 0.9877\n",
      "Train Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9917    0.9917    0.9917       605\n",
      "           1     0.9868    0.9803    0.9835       152\n",
      "           2     0.9765    0.9881    0.9822       168\n",
      "           3     0.9895    0.9792    0.9843        96\n",
      "           4     0.9767    0.9655    0.9711        87\n",
      "           5     0.9907    1.0000    0.9953       107\n",
      "\n",
      "    accuracy                         0.9877      1215\n",
      "   macro avg     0.9853    0.9841    0.9847      1215\n",
      "weighted avg     0.9877    0.9877    0.9876      1215\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 8/8 [00:00<00:00, 16.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.3484\n",
      "Accuracy: 0.6098\n",
      "Macro F1: 0.5064\n",
      "Micro F1: 0.6098\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7903    0.6447    0.7101        76\n",
      "           1     0.3714    0.6842    0.4815        19\n",
      "           2     0.5455    0.4286    0.4800        14\n",
      "           3     0.4444    0.6667    0.5333         6\n",
      "           4     0.5000    0.5000    0.5000         4\n",
      "           5     0.5000    0.2500    0.3333         4\n",
      "\n",
      "    accuracy                         0.6098       123\n",
      "   macro avg     0.5253    0.5290    0.5064       123\n",
      "weighted avg     0.6620    0.6098    0.6209       123\n",
      "\n",
      "\n",
      "🌟 Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:17<00:00,  4.45it/s]\n",
      "Evaluating: 100%|██████████| 76/76 [00:04<00:00, 16.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0379\n",
      "Train Accuracy: 0.9901\n",
      "Train Macro F1: 0.9891\n",
      "Train Micro F1: 0.9901\n",
      "Train Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9967    0.9884    0.9925       605\n",
      "           1     0.9868    0.9868    0.9868       152\n",
      "           2     0.9709    0.9940    0.9824       168\n",
      "           3     0.9897    1.0000    0.9948        96\n",
      "           4     0.9773    0.9885    0.9829        87\n",
      "           5     1.0000    0.9907    0.9953       107\n",
      "\n",
      "    accuracy                         0.9901      1215\n",
      "   macro avg     0.9869    0.9914    0.9891      1215\n",
      "weighted avg     0.9902    0.9901    0.9901      1215\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 8/8 [00:00<00:00, 16.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.2298\n",
      "Accuracy: 0.6504\n",
      "Macro F1: 0.4761\n",
      "Micro F1: 0.6504\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7671    0.7368    0.7517        76\n",
      "           1     0.4615    0.6316    0.5333        19\n",
      "           2     0.6000    0.4286    0.5000        14\n",
      "           3     0.5000    0.6667    0.5714         6\n",
      "           4     0.5000    0.5000    0.5000         4\n",
      "           5     0.0000    0.0000    0.0000         4\n",
      "\n",
      "    accuracy                         0.6504       123\n",
      "   macro avg     0.4714    0.4939    0.4761       123\n",
      "weighted avg     0.6542    0.6504    0.6479       123\n",
      "\n",
      "\n",
      "🌟 Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:17<00:00,  4.46it/s]\n",
      "Evaluating: 100%|██████████| 76/76 [00:04<00:00, 16.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0278\n",
      "Train Accuracy: 0.9909\n",
      "Train Macro F1: 0.9901\n",
      "Train Micro F1: 0.9909\n",
      "Train Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9934    0.9917    0.9926       605\n",
      "           1     0.9934    0.9868    0.9901       152\n",
      "           2     0.9766    0.9940    0.9853       168\n",
      "           3     1.0000    0.9896    0.9948        96\n",
      "           4     0.9884    0.9770    0.9827        87\n",
      "           5     0.9907    1.0000    0.9953       107\n",
      "\n",
      "    accuracy                         0.9909      1215\n",
      "   macro avg     0.9904    0.9899    0.9901      1215\n",
      "weighted avg     0.9910    0.9909    0.9910      1215\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 8/8 [00:00<00:00, 16.69it/s]\n",
      "d:\\newargmining\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\newargmining\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\newargmining\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\newargmining\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.2733\n",
      "Accuracy: 0.6667\n",
      "Macro F1: 0.4828\n",
      "Micro F1: 0.6667\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7500    0.7895    0.7692        76\n",
      "           1     0.4231    0.5789    0.4889        19\n",
      "           2     0.6667    0.4286    0.5217        14\n",
      "           3     0.6000    0.5000    0.5455         6\n",
      "           4     0.6667    0.5000    0.5714         4\n",
      "           5     0.0000    0.0000    0.0000         4\n",
      "\n",
      "    accuracy                         0.6667       123\n",
      "   macro avg     0.5177    0.4662    0.4828       123\n",
      "weighted avg     0.6556    0.6667    0.6554       123\n",
      "\n",
      "\n",
      "🌟 Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:17<00:00,  4.46it/s]\n",
      "Evaluating: 100%|██████████| 76/76 [00:04<00:00, 16.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0246\n",
      "Train Accuracy: 0.9909\n",
      "Train Macro F1: 0.9901\n",
      "Train Micro F1: 0.9909\n",
      "Train Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9917    0.9934    0.9926       605\n",
      "           1     0.9934    0.9868    0.9901       152\n",
      "           2     0.9822    0.9881    0.9852       168\n",
      "           3     1.0000    0.9896    0.9948        96\n",
      "           4     0.9884    0.9770    0.9827        87\n",
      "           5     0.9907    1.0000    0.9953       107\n",
      "\n",
      "    accuracy                         0.9909      1215\n",
      "   macro avg     0.9911    0.9892    0.9901      1215\n",
      "weighted avg     0.9910    0.9909    0.9909      1215\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 8/8 [00:00<00:00, 16.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.3258\n",
      "Accuracy: 0.6585\n",
      "Macro F1: 0.4828\n",
      "Micro F1: 0.6585\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7564    0.7763    0.7662        76\n",
      "           1     0.4545    0.5263    0.4878        19\n",
      "           2     0.6000    0.4286    0.5000        14\n",
      "           3     0.5000    0.6667    0.5714         6\n",
      "           4     0.6667    0.5000    0.5714         4\n",
      "           5     0.0000    0.0000    0.0000         4\n",
      "\n",
      "    accuracy                         0.6585       123\n",
      "   macro avg     0.4963    0.4830    0.4828       123\n",
      "weighted avg     0.6520    0.6585    0.6522       123\n",
      "\n",
      "\n",
      "🌟 Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 76/76 [00:17<00:00,  4.43it/s]\n",
      "Evaluating: 100%|██████████| 76/76 [00:04<00:00, 16.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0241\n",
      "Train Accuracy: 0.9918\n",
      "Train Macro F1: 0.9912\n",
      "Train Micro F1: 0.9918\n",
      "Train Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9950    0.9917    0.9934       605\n",
      "           1     0.9934    0.9868    0.9901       152\n",
      "           2     0.9766    0.9940    0.9853       168\n",
      "           3     1.0000    0.9896    0.9948        96\n",
      "           4     0.9885    0.9885    0.9885        87\n",
      "           5     0.9907    1.0000    0.9953       107\n",
      "\n",
      "    accuracy                         0.9918      1215\n",
      "   macro avg     0.9907    0.9918    0.9912      1215\n",
      "weighted avg     0.9918    0.9918    0.9918      1215\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 8/8 [00:00<00:00, 17.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.3538\n",
      "Accuracy: 0.6748\n",
      "Macro F1: 0.4950\n",
      "Micro F1: 0.6748\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7867    0.7763    0.7815        76\n",
      "           1     0.4800    0.6316    0.5455        19\n",
      "           2     0.6000    0.4286    0.5000        14\n",
      "           3     0.5000    0.6667    0.5714         6\n",
      "           4     0.6667    0.5000    0.5714         4\n",
      "           5     0.0000    0.0000    0.0000         4\n",
      "\n",
      "    accuracy                         0.6748       123\n",
      "   macro avg     0.5056    0.5005    0.4950       123\n",
      "weighted avg     0.6746    0.6748    0.6705       123\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\n🌟 Epoch {epoch + 1}/{EPOCHS}\")\n",
    "    \n",
    "    train_loss, train_acc = train_epoch(model, train_loader, optimizer, criterion, lr_scheduler)\n",
    "    evaluation_results = evaluate(model, train_loader, criterion)\n",
    "    print(f\"Train Loss: {evaluation_results['loss']:.4f}\")\n",
    "    print(f\"Train Accuracy: {evaluation_results['accuracy']:.4f}\")\n",
    "    print(f\"Train Macro F1: {evaluation_results['macro_f1']:.4f}\")\n",
    "    print(f\"Train Micro F1: {evaluation_results['micro_f1']:.4f}\")\n",
    "    print(f\"Train Classification Report:\\n{evaluation_results['classification_report']}\")\n",
    "    \n",
    "    evaluation_results = evaluate(model, val_loader, criterion)\n",
    "    print(f\"Loss: {evaluation_results['loss']:.4f}\")\n",
    "    print(f\"Accuracy: {evaluation_results['accuracy']:.4f}\")\n",
    "    print(f\"Macro F1: {evaluation_results['macro_f1']:.4f}\")\n",
    "    print(f\"Micro F1: {evaluation_results['micro_f1']:.4f}\")\n",
    "    print(f\"Classification Report:\\n{evaluation_results['classification_report']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 8/8 [00:00<00:00, 16.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.2053\n",
      "Accuracy: 0.7236\n",
      "Macro F1: 0.5786\n",
      "Micro F1: 0.7236\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8052    0.8158    0.8105        76\n",
      "           1     0.7143    0.7895    0.7500        19\n",
      "           2     0.5000    0.4000    0.4444        15\n",
      "           3     0.4000    0.4000    0.4000         5\n",
      "           4     0.4000    0.4000    0.4000         5\n",
      "           5     0.6667    0.6667    0.6667         3\n",
      "\n",
      "    accuracy                         0.7236       123\n",
      "   macro avg     0.5810    0.5787    0.5786       123\n",
      "weighted avg     0.7176    0.7236    0.7196       123\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "evaluation_results = evaluate(model, test_loader, criterion)\n",
    "print(f\"Loss: {evaluation_results['loss']:.4f}\")\n",
    "print(f\"Accuracy: {evaluation_results['accuracy']:.4f}\")\n",
    "print(f\"Accuracy: {evaluation_results['accuracy']:.4f}\")\n",
    "print(f\"Macro F1: {evaluation_results['macro_f1']:.4f}\")\n",
    "print(f\"Micro F1: {evaluation_results['micro_f1']:.4f}\")\n",
    "print(f\"Classification Report:\\n{evaluation_results['classification_report']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('roberta_aug_final_metrics\\\\tokenizer_config.json',\n",
       " 'roberta_aug_final_metrics\\\\special_tokens_map.json',\n",
       " 'roberta_aug_final_metrics\\\\vocab.json',\n",
       " 'roberta_aug_final_metrics\\\\merges.txt',\n",
       " 'roberta_aug_final_metrics\\\\added_tokens.json',\n",
       " 'roberta_aug_final_metrics\\\\tokenizer.json')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"roberta_aug_final_metrics\")\n",
    "tokenizer.save_pretrained(\"roberta_aug_final_metrics\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Misclassification Analysis by Class\n",
    "Class 0: Appeal to Emotion (63/76 correct, 82.89%)\n",
    "\n",
    "Misclassified as Appeal to Authority (Class 1): 7 instances\n",
    "Misclassified as Ad Hominem (Class 2): 3 instances\n",
    "Misclassified as False Cause (Class 3): 3 instances\n",
    "\n",
    "Class 1: Appeal to Authority (13/19 correct, 68.42%)\n",
    "\n",
    "Misclassified as Appeal to Emotion (Class 0): 4 instances\n",
    "Misclassified as False Cause (Class 3): 2 instances\n",
    "\n",
    "Class 2: Ad Hominem (3/15 correct, 20.00%)\n",
    "\n",
    "Misclassified as Appeal to Emotion (Class 0): 10 instances\n",
    "Misclassified as Appeal to Authority (Class 1): 2 instances\n",
    "\n",
    "Class 3: False Cause (1/5 correct, 20.00%)\n",
    "\n",
    "Misclassified as Appeal to Emotion (Class 0): 3 instances\n",
    "Misclassified as Appeal to Authority (Class 1): 1 instance\n",
    "\n",
    "Class 4: Slippery Slope (0/5 correct, 0.00%)\n",
    "\n",
    "Misclassified as Appeal to Emotion (Class 0): 3 instances\n",
    "Misclassified as Ad Hominem (Class 2): 2 instances\n",
    "\n",
    "Class 5: Slogans (1/3 correct, 33.33%)\n",
    "\n",
    "Misclassified as Appeal to Emotion (Class 0): 2 instances\n",
    "\n",
    "Key Observations:\n",
    "\n",
    "Appeal to Emotion (Class 0) acts as a \"catch-all\" category for the model, with most misclassifications from other classes going to this category.\n",
    "Ad Hominem (Class 2) is heavily misclassified as Appeal to Emotion (10/15), representing the worst recognition among major classes.\n",
    "Slippery Slope (Class 4) has a 0% accuracy rate, with most instances misclassified as Appeal to Emotion."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
